# ASUhumanrobotcomp2018
ASU Human Robot Companion Competition Prep


**File Explanations**

nodeJShelloWorld - sends commands to an ROS turtlesim over Javascript

TerminalDiaries - A Diary of Terminal Commands

killroscore - "./killroscore" to kill ros processes (you might need to chmod +x first)

ros_start - "./rosstart" executable to set up wireless communications


**Things to work on:**

Grasping point
**Reasoning to find objects in certain positions
What type of ML? CNN?
Noise? What levels
Gmapping
Simulate? What to simulate
**What information can we draw from the robot? Position? Localization?
Performance of Javascript? Underlying control module
Assessment Schedule 

** Mehrdad's notes**
-work through room
-get picture (how to take image and preform algo on image)
-find some packages (with CNN) in ROS that do object recognition on those images
-WIRESHARK (monitors all ingoing/outgoing ports on computer on ports) Find Message Data
-grasping and moving object and mistakes



**Moving forward 4/18 **
-We need to write code to pull data
-Use Overleaf and Latex to document team data

**Topics to look at**
-Ros Wiki Messages >> Rosmsg >> view header and complex messages
-json-like formatted messages 
    -ros.org/Topics >> 
-ros.org/rsqt_graph shows package to package transmissions
-rviz shows messages you recieve from robot, visualizes information from sensors, helps get a high level picture (what sensors are returning)
-Talked about example of connecting with Xbox Kinect (has the same ROS functionality for vision as handyman) >> Next meeting demonstration
-Catkin
-Make a description of what we've done so far.



